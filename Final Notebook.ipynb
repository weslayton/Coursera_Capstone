{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Pharmacy Density in Toronto: Increasing Access to Medicine\n## Introduction / Business Problem\nIn the city of Toronto, with an approximate population of 6,341,935, there is a need for advanced and expanding health infrastructure. Within healthcare, pharmacy and prescription drugs are at the forefront of discussion with rising costs. With barriers already in the form of costs, it is important for the health of a population to be able to access these drugs conveniently and adhere to the guidelines given.\n\nI will seek to find the neighborhoods in Toronto where there is a lack of pharmacies and hopefully identify the single neighborhood with the greatest need. This information could be key for any investors that are looking to open an independent pharmacy, or for recent pharmacy graduates that are also looking to open and run their own independent pharmacy. By contextualizing the neighborhoods in terms of the density of pharmacies and neighborhood population, they will be able to make decisions to best serve the greater Toronto area and its citizens.\n\n## Data\nI will use Foursquare location data and web scraped postal codes from Wikipedia to be able to analyze neighborhoods and their pharmacy density. This data will be drawn through Foursquare's API by defining the search parameters for each neighborhood as nearby pharmacies and then joining this to our postal codes for the Toronto area.\n\nI will also be using population data from the 2016 census that is available through the Statistics Canada government website in CSV format (https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/hlt-fst/pd-pl/Table.cfm?Lang=Eng&T=1201&S=22&O=A). This data contains raw population numbers for each postal code and will also be joined to our data frame so that we are able to contextualize the need for pharmacies as it is compared to the total population of the postal code.\n\n## Goals in this Notebook\n\n- Build a dataframe of neighborhoods in Toronto by web scraping the data from the Wikipedia page.\n- Get the geographical coordinates of the neighborhoods and plot these neighborhoods.\n- Obtain the venue data for the pharmacies of these areas from the Foursquare API.\n- Explore and cluster the neighborhoods.\n- Select the best cluster to open a new pharmacy.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installing all packages needed.\n\nimport numpy as np # library to handle data in a vectorized manner\n\nimport pandas as pd # library for data analsysis\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\n\nimport json # library to handle JSON files\n\n!conda install -c conda-forge geopy --yes\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n\nimport requests # library to handle requests\nfrom pandas.io.json import json_normalize # tranform JSON file into a pandas dataframe\n\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n#!conda install -c conda-forge folium=0.5.0\nimport folium # map rendering library\n\n# Plotly for visualizations\nimport plotly.graph_objects as go\nimport plotly.express as px\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\n\n# Packages for web-scraping\nimport urllib.request\nfrom bs4 import BeautifulSoup\n\n\nprint('Libraries imported.')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Web-Scraping our Data"},{"metadata":{},"cell_type":"markdown","source":"First, we will need to webscrape a Wikipedia page containing all of Canada's postal codes to be able to segment and plot our Toronto neighborhoods. For this we will use BeautifulSoup and URLLib."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining our target URL\nurl = \"https://en.wikipedia.org/wiki/List_of_postal_codes_of_Canada:_M\"\n\n# Setting it up to open with BeautifulSoup\npage = urllib.request.urlopen(url)\nsoup = BeautifulSoup(page, \"lxml\")\n\n# Identifying the table and rows we will be scraping from\ntable = soup.find('table',{'class':'wikitable'})\ntable_rows = table.find_all('tr')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will write a loop to find all of our FSAs. The way we find it will group them all together in one column, so the rest of the lines will be to break them apart into separate columns and format to the specifications in the assignment."},{"metadata":{"trusted":true},"cell_type":"code","source":"data = []\nfor row in table_rows:\n    data.append([t.text.strip() for t in row.find_all('td')])\n\ndf = pd.DataFrame(data, columns=['PostalCode','Borough','Neighborhood'])\ndf = df[df.Borough.str.contains(\"Not assigned\") == False] # Removing any Postal Codes that are not assigned\ndf.Neighborhood.fillna(df.Borough, inplace=True) # Filling blank neighborhood values with the corresponding Borough\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Joining Lat & Lon Values\n\nNow that we have our MSA data, we will need to bring in our geospatial coordinates.\nFirst, we'll read the geospatial CSV."},{"metadata":{"trusted":true},"cell_type":"code","source":"gsp = pd.read_csv('../input/geospatial-coordinates/Geospatial_Coordinates.csv')\npop = pd.read_csv('../input/toronto-2016-population/TorontoPop.csv') # we will also go ahead and load our population numbers","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can simply merge on our Postal Code values and that will leave us with the previous dataframe with the addition of lat & lon values. We will drop the redundant Postal Code column."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Performing an inner merge with our coordinates\ndf2 = df.merge(gsp, how='inner', left_on='PostalCode', right_on='Postal Code')\ndf2 = df2.drop(['Postal Code'], axis=1) # Dropping redundant postal code value\n# Joining to our population data\ndf2 = df2.merge(pop, how='inner', left_on='PostalCode', right_on='Geographic code')\ndf2 = df2.drop(['Geographic code'], axis=1) # Dropping redundant value\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotting our Neighborhoods with Folium"},{"metadata":{},"cell_type":"markdown","source":"Now that we have our joined table, let's plot our neighborhoods. First we will need the central coordinates for Toronto. We can find this with the Nominatim from the geopy.geocode package."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining our city\naddress = 'Toronto, CA'\n\ngeolocator = Nominatim(user_agent=\"toronto_explorer\")\nlocation = geolocator.geocode(address)\n\n# Naming our coordinates\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinates of Toronto are {}, {}.'.format(latitude, longitude))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Limiting our boroughs to only those containing the word Toronto so that we aren't plotting all of Canada's postal codes.\ntoronto_data = df2[df2.Borough.str.contains(\"Toronto\") == True]\ntoronto_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create map of Toronto using latitude and longitude values\nmap_toronto = folium.Map(location=[latitude, longitude], zoom_start=10)\n\n# add markers to map\nfor lat, lng, borough, neighborhood in zip(toronto_data['Latitude'], toronto_data['Longitude'], toronto_data['Borough'], toronto_data['Neighborhood']):\n    label = '{}, {}'.format(neighborhood, borough)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_toronto)  \n    \nmap_toronto","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Foursquare API for Venue Data"},{"metadata":{},"cell_type":"markdown","source":"Time to begin gaining our venue data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining our Foursquare credentials:\nCLIENT_ID = 'QP3VVQK1XEFRVYOJRIZK22I3LYJZ23GWE5QNQW0I3M3XVI2M' # your Foursquare ID\nCLIENT_SECRET = 'QCKLK1WG0Z3C1NT3FSWYFNVOHOCN2JQ01BZSIHWINBRM0T0X' # your Foursquare Secret\nVERSION = '20200323' # Foursquare API version\nLIMIT = '100'\nRADIUS = '500'\nQUERY = 'pharmacy'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below we will now write a function to make an API call for pharmacies in each of our neighborhoods."},{"metadata":{"trusted":true},"cell_type":"code","source":"LIMIT = 500  # limit of number of venues returned by Foursquare API\nsearch_query = 'Pharmacy'\n\ndef getNearbyVenues(names, latitudes, longitudes, radius=1000):\n\n    venues_list = []\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n\n        # create the API request URL\n        url = \"https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&ll={},{}&v={}&query={}&radius={}&limit={}\".format(\n            CLIENT_ID, CLIENT_SECRET, lat, lng, VERSION, search_query, radius, LIMIT\n        )\n\n        # make the GET request\n        try:\n            results = requests.get(url).json()[\"response\"][\"groups\"][0][\"items\"]\n        except:\n            print(\"can't get request results from url\")\n\n        # return only relevant information for each nearby venue\n        venues_list.append(\n            [\n                (\n                    name,\n                    lat,\n                    lng,\n                    v[\"venue\"][\"name\"],\n                    v[\"venue\"][\"location\"][\"lat\"],\n                    v[\"venue\"][\"location\"][\"lng\"],\n                    v[\"venue\"][\"categories\"][0][\"name\"],\n                    v[\"venue\"][\"id\"],\n                )\n                for v in results\n            ]\n        )\n\n    nearby_venues = pd.DataFrame(\n        [item for venue_list in venues_list for item in venue_list]\n    )\n    nearby_venues.columns = [\n        \"Neighborhood\",\n        \"NeighborhoodLatitude\",\n        \"NeighborhoodLongitude\",\n        \"Venue\",\n        \"VenueLatitude\",\n        \"VenueLongitude\",\n        \"VenueCategory\",\n        \"VenueID\"\n    ]\n\n    return nearby_venues","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we can execute it by supplying our Neighborhood and geo data."},{"metadata":{"trusted":true},"cell_type":"code","source":"toronto_venues = getNearbyVenues(names=toronto_data['Neighborhood'],\n                                   latitudes=toronto_data['Latitude'],\n                                   longitudes=toronto_data['Longitude']\n                                  )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(toronto_venues.shape)\ntoronto_venues.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that we have all of our venue data in a pandas df we can begin to group by neighborhoods and analyze our findings. First we can get a count of distinct categories."},{"metadata":{"trusted":true},"cell_type":"code","source":"toronto_venues.groupby('Neighborhood').count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Neighborhood Analysis"},{"metadata":{},"cell_type":"markdown","source":"We can now group by neighborhood and find the count of pharmacies in each area."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Naming a new df that is grouped by neighborhood and counts pharmacies\ntoronto_grouped = toronto_venues.groupby('Neighborhood').count().reset_index()\n\n# Joining back our original data and removing unnessecary rows\ntoronto_grouped = toronto_grouped.merge(toronto_data, how='inner', left_on='Neighborhood', right_on='Neighborhood')\ntoronto_grouped = toronto_grouped.drop(['Borough'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['PostalCode'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['NeighborhoodLatitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['NeighborhoodLongitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['Venue'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['VenueLatitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['VenueLongitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['VenueCategory'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['Latitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['Longitude'], axis=1)\ntoronto_grouped = toronto_grouped.drop(['Population, 2016'], axis=1)\n\n# Naming the columns\ntoronto_grouped.columns = ['Neighborhood','PharmacyCount']\n\n# Displaying our new df\ntoronto_grouped.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Clustering Neighborhoods"},{"metadata":{},"cell_type":"markdown","source":"We can move on to clustering our neighborhoods, we'll begin below using k-means clustering."},{"metadata":{"trusted":true},"cell_type":"code","source":"# set number of clusters\nkclusters = 5\n\ntoronto_grouped_clustering = toronto_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(toronto_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_[0:10] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add clustering labels\ntoronto_grouped.insert(0, 'Cluster Labels', kmeans.labels_)\n\ntoronto_merged = toronto_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\ntoronto_merged = toronto_merged.merge(toronto_grouped,how='inner', on='Neighborhood')\ntoronto_merged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And finally, we'll map our clusters!"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=11)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(toronto_merged['Latitude'], toronto_merged['Longitude'], toronto_merged['Neighborhood'], toronto_merged['Cluster Labels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Finding the Optimal Cluster"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Grouping by cluster and dropping geo data\ntoronto_cluster = toronto_merged.groupby('Cluster Labels').sum()\ntoronto_cluster = toronto_cluster.drop(['Latitude'], axis=1)\ntoronto_cluster = toronto_cluster.drop(['Longitude'], axis=1)\n\ntoronto_cluster","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can see which clusters has the most population living in it below with the use of Matplotlib for visualization."},{"metadata":{"trusted":true},"cell_type":"code","source":"toronto_cluster.groupby('Cluster Labels').sum()['Population, 2016'] \\\n    .sort_values() \\\n    .plot(kind='bar', figsize=(15, 5), title= 'Population per Cluster')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"While that is good, our ultimate test will be the amount of pharmacies per population. Once we see this, we can easily decide which cluster has the greatest potential success for a new pharmacy."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding Pharmacy Density Per Population by dividing the number of pharmacies by population for each cluster\ntoronto_cluster['PharmaciesPerPop'] = toronto_cluster['PharmacyCount']/toronto_cluster['Population, 2016']\ntoronto_cluster = toronto_cluster.sort_values(by='PharmaciesPerPop',ascending=True)\ntoronto_cluster = toronto_cluster.reset_index()\n\n# Displaying the results in a bar chart\ntoronto_cluster.groupby('Cluster Labels').sum()['PharmaciesPerPop'] \\\n    .sort_values() \\\n    .plot(kind='bar', figsize=(15, 5), title= 'Pharmacy Denisty in Clusters per Population')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\nIn this project we have identified the business problem of locating the best area for a new pharmacy in Toronto. We were able to gain the necessary data through sources online and web-scrape for what was needed. Once we had the data we prepared it for analysis and explored through Folium maps. Once this was complete we utilized machine learning through K-means clustering by grouping neighborhoods based on their similarity. Once we had done this we could finally make the suggestions to stakeholders on which cluster was most effective for the launch of a new pharmacy. Through our analysis we found that Cluster 2 proved to have the most potential for providing better access for more people in the city of Toronto."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Writing our df's to CSV files.\ntoronto_data.to_csv('toronto_data.csv',index=False)\ntoronto_venues.to_csv('toronto_venues.csv',index=False)\ntoronto_grouped.to_csv('toronto_cluster.csv',index=False)\ntoronto_merged.to_csv('toronto_cluster.csv',index=False)\ntoronto_cluster.to_csv('toronto_cluster.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}